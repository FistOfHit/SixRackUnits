[![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/assets/header.png)](https://sixrackunits.substack.com)

# May 2025

![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/newsletters/2025/may_2025/images/title.jpeg)

*What if interconnects became zero-latency over any distance? What about zero-latency for multiplexing/de-multiplexing, buffering, decoding etc.? Or what if there was no latency between a chip accessing a memory region in any other chip it was working with, regardless of where that other chip is? How would that change compute and memory?*

This is the SixRackUnits AI hardware newsletter, keeping you up to date with the latest in AI hardware, datacenter technology, and the future of compute. In addition, we also cover small-time vendors of anything interesting in the space, as well as short "one-pagers" on a random topic that we find interesting (and hope you do too).

For a space to share sources and news/updates, join on <a href="https://t.me/aihpc_infra_fans">Telegram</a>, and check out my <a href="https://www.linkedin.com/in/hitesh-kumar58">LinkedIn</a> for posts on similar topics!

**Note**: From this issue onwards, the number of one-pagers (segments aimed at explaining a concept in a single page) will be limited to one per month. With an increase in writing on LinkedIn, I will be sharing a lot of content there that will be similar in nature to the one-pagers, but this comes at the cost of having less time to work on this newsletter. I apologise in advance.

[**This month's updates:**](#this-months-updates)
  - [**Nvidia's ASICs for China - post-diffusion act**](#nvidias-asics-for-china-post-diffusion-act)
  - [**Apple reportedly working on the next four generations of chips**](#apple-reportedly-working-on-the-next-four-generations-of-chips)
  - [**Nvidia opens up NVLink for custom CPUs and AI accelerators - NVLink fusion**](#nvidia-opens-up-nvlink-for-custom-cpus-and-ai-accelerators---nvlink-fusion)
  - [**Other notable headlines**](#other-notable-headlines)

[**Vendor spotlight:**](#vendor-spotlight)
  - [**iPronics**](#ipronics)

[**One-pager:**](#one-pager)
  - [**Wave Division Multiplexing**](#wave-division-multiplexing)

---

# This month's updates:

## Nvidia's new blackwell GPUs for China - unwavering resolve despite U.S. policy

**

## Apple reportedly working on the next four generations of M-series chips

**

## Nvidia opens up NVLink for custom CPUs and AI accelerators - NVLink fusion

**

## Intel releases the PCIe form-factor of their Gaudi 3 AI accelerator

*Intel has long since terminated their Gaudi roadmap, ending the lineage of the AI accelerators made by the acquired Habana Labs in favour for a joint Intel-Habana architecture called Falcon/Jaguar shores, due 2026. In the meanwhile, Intel has released (on schedule) the surprisingly competitive PCIe form factor of their final accelerator in this series, the Gaudi 3.*

![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/newsletters/2025/may_2025/images/intel_pciecard.png)

The Gaudi 3 "add-on" card, codenamed the [HL-338](https://www.intel.com/content/www/us/en/content-details/817488/intel-gaudi-3-ai-accelerator-hl-338-pcie-add-in-card-product-brief.html), is a FHFL (full-height, full length) double-width PCIe card supporting 16 lanes of PCIe gen. 5, designed to be added into medium/large AI/HPC servers, has just been released. Originally announced in 2Q24 as part of Intel's now discontinued roadmap for the Gaudi AI accelerator series, the HL-338 is intended for both training and inference workloads as a standalone card or as part of a reference architecture. The official documentation describes four interconnected cards using 3/4 of their network bandwidth to form a fully-connected mesh scale-up network, and 1/4 for scale-out via host NICs.

![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/newsletters/2025/may_2025/images/intel_diagram.png)

Habana Labs originally developed the Gaudi series independently and in parallel to Intel's own "Max" series of GPUs, but as early as 2Q23, [Intel announced](https://www.tomshardware.com/news/intel-explains-falcon-shores-redefinition-shares-roadmap-and-first-details) the merging of the two technologies into one product line, codenamed the Falcon shores. Shortly afterwards, Intel also declared that they would [no longer](https://www.hpcwire.com/2024/09/17/intels-falcon-shores-future-looks-bleak-as-it-concedes-ai-training-to-gpu-rivals/) be designing the new merged GPU around AI training, but for Inference and HPC workloads only. Further, just 3 months later they [scrapped Falcon shores](https://www.tomshardware.com/tech-industry/artificial-intelligence/intel-cancels-falcon-shores-gpu-for-ai-workloads-jaguar-shores-to-be-successor)(a PCIe form factor card) from their sales plans and stated that they would focus on their [Jaguar shores](https://www.tomshardware.com/tech-industry/artificial-intelligence/intel-redefines-ai-strategy-jaguar-shores-to-be-rack-level-design-with-focus-on-silicon-photonics) (larger OAM card), with an emphasis on rack-scale systems just as Nvidia and now AMD are doing.

![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/newsletters/2025/may_2025/images/intel_roadmap_old.png)

Rack scale solutions also exist, but are in the form of [reference architectures](https://www.intel.com/content/www/us/en/content-details/817486/intel-gaudi-3-ai-accelerator-white-paper.html) only, not custom racks like Nvidia's NVL72 or AMD's upcoming [IF64/128](https://semianalysis.com/2025/04/23/amd-2-0-new-sense-of-urgency-mi450x-chance-to-beat-nvidia-nvidias-new-moat/) solutions. That being said, the reference architectures are comprehensive and provide guidance on the rack layouts, network topologies, and even server/fabric configurations for developers and engineers to follow. 

Finally, the specs ([1](https://www.intel.com/content/www/us/en/content-details/817488/intel-gaudi-3-ai-accelerator-hl-338-pcie-add-in-card-product-brief.html) [2](https://www.intel.com/content/www/us/en/content-details/817486/intel-gaudi-3-ai-accelerator-white-paper.html) [3](https://www.intel.com/content/www/us/en/content-details/817489/intel-gaudi-3-ai-accelerator-hlb-325-baseboard-product-brief.html) [4](https://www.synopsys.com/blogs/chip-design/soc-hbm2e-capacity-speed-benefits.html)):
- ~1.8 PFLOPs of BF16
- 96MB SRAM @ 12.8 TB/s bandwidth
- 128GB HBM2E @ 3.7TB/s (8 stacks of 12hi from SK-Hynix most likely)
- 64GB/s H2D bandwidth via PCIe gen. 5 x16
- Using TSMC's 5nm process
- 600W TDP
AND:
- Single card: Up to 4.8TB/s aggregate scale-out bandwidth via 24 x 200G RoCE ports (48 lanes @ 112G)
OR
- 4 x cards: Up to 4.8TB/s aggregate scaleout + 14.4TB/s aggregate scale-up (1:3 ratio scale-out:scale-up)

##

**


## Other notable headlines

* [Nvidia might postpone the adoption of SOCAMM LPDDR5X modules for its GB300 boards, sources cite thermal issues and stability problems](https://zdnet.co.kr/view/?no=20250514101636)
* [Nvidia's 1.6T optical transceiver's likely delayed from 4Q25 to 1Q26, sources cite supply chain issues](https://www.digitimes.com.tw/tech/dt/n/shwnws.asp?CnlID=1&Cat=40&id=0000721735_JVO6R7644LFNHC4YWMO00)
* [AMD's Venice CPUs (2026) confirmed to use TSMC's 2nm process - "TSMC is the leader in 2nm", AMD states](https://www.tweaktown.com/news/105305/amd-says-tsmcs-new-2nm-node-is-superior-to-all-alternatives-talks-using-samsung-foundry/index.html)
* [Nvidia's Connectx-8 NICs to come with PCIe 6.0 switches inside - acting as the interface between CPU and two GPUs each](https://developer.nvidia.com/blog/nvidia-connectx-8-supernics-advance-ai-platform-architecture-with-pcie-gen6-connectivity/)
* [IBM releases the LinuxONE Emperor 5 platform - Mainframe, but without the need to survive an earthquake](https://www.ibm.com/products/linuxone-5)
---

# Vendor spotlight:

## iPronics

*Datacenter switching is reaching a point where the relative power draw of the optical-electrical interfaces (transceivers) required to carry the extreme bandwidths of AI fabrics is becoming a concern. 800G fabrics now need special transceiver casings, as well as taller ports just to stay cool. One way to avoid scaling implementation and integration difficulty is to use optical circuit switching, or OCS.*

![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/newsletters/2025/may_2025/images/ipronics_logo.png)

Founded in 2019, Spanish startup [iPronics](https://ipronics.com/) focusing on "software-defined photonics", or photonics hardware designed to be programmable and reconfigurable. iPronics' OCS technology seeks to replace power hungry and fixed-bandwidth electrical switches in datacenters with photonic (light-based) switches that route optical signals without converting them to electrical signals.

Electrical conversion requires significant amounts of power, maintenance, and specialised hardware to support a limited number bandwidths based on the signal processor design. For example, a 400G switch (referred to as a 25.6T switch by aggregating its 64 ports) requires datacenter staff to use a guide on plugging in the right cable into the right transceiver into the right port, in a particular pattern in order to cable up a particular topology. In addition, these transceivers can only support 400G, 2 x 200G, or 4 x 100G bandwidths usually, and upgrading to higher bandwidths requires new switch ASICs, ports, and transceivers.

![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/newsletters/2025/may_2025/images/ipronics_puc.gif)

*Source: iPronics*

Their ["ONE" switch](https://ipronics.com/ipronics-optical-networking-engine/) is a 32-port 1U switch based on their [programmable unit cell](https://ipronics.com/technology/) technology, which is a versatile compute/switching unit that can be combined into structures of seemingly arbitrary size to create something analogous to a switch ASIC with compute attached. Using this, the OCS device can not only route and process signals on the same package, but can also be reconfigured via software to modify the routing and processing within 100s of microseconds. This means that in theory, switches made from these programmable unit cells should be able to support in-network compute as well as rapid topology changes to the fabric without extensive maintenance and costly downtime.

![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/newsletters/2025/may_2025/images/ipronics_one.png)

*Source: iPronics*

Finally, the specs for the ONE switch are as follows:
- 32 ports independent of bandwidth (up to some limits most likely)
- 1U form factor with 8 physical ports it seems
- <30ns switching latency (compared to 500-1000ns for high end electrical switches)
- <300 microseconds reconfiguration time compared to 100s of milliseconds for mirror-based optical switches

---

# One-pager:

## Wave Division Multiplexing

*Optical fibre itself does have a limit to how much bandwidth it can carry, but current technology is not yet at that wall. To increase bandwidths for cables that need to carry multiple signals at once, one method is wave-division multiplexing (WDM), using multiple wavelengths (or colours) of light to simultaneously carry multiple distinct signals through one fibre.*

WDM is used widely in industry for long range optical communication such as undersea cables, telecoms networks, and more recently, datacenter interconnects. It is a method of multiplexing multiple signals over a single optical fibre by using different wavelengths (or colours) of light. Each wavelength carries its own data stream, and the combined signals are transmitted over a single fibre. At the receiving end, a de-multiplexer separates the combined signals back into their original wavelengths.

![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/newsletters/2025/may_2025/images/wdm_architecture.png)

*Source: MEETOPTICS*

Initially, WDM in the 1980s used four wavelengths of light at around ~850nm, but since then the technology has advanced to allow for an order of magnitude more of wavelengths at much higher wavelengths of between 1525-1610nm. WDM that uses a few, widely spaced set of wavelengths is now called coarse WDM (CWDM), while more modern dense WDM (DWDM) uses many closely spaced wavelengths. The latter is the most common in use today, with some practical implementations enabling up to 96 distinct wavelengths to be carried over a single fibre. Using a modern 400G signal, DWDM would allow for an effective bandwidth of 96x400Gbps or 38Tbps over a single fibre.

![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/newsletters/2025/may_2025/images/wdm_spacing.png)

*Source: Neos networks*

Using narrower gaps between wavelengths requires more precise hardware to avoid signal loss due to interference and attenuation, but the limitations of existing fibre optics technology leaves no other option. Due to various physical phenomena and interactions between light and the glass fibre, certain bands of wavelengths result is less signal loss than others. The C and L bands (1530-1565nm and 1565-1625nm respectively) are the most commonly ranges used for DWDM, and increasing the number of distinct usable wavelengths in these bands requires narrowing the gaps between them.

![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/newsletters/2025/may_2025/images/wdm_bands.jpg)

*Source: Pandacomdirekt*

[![](https://raw.githubusercontent.com/FistOfHit/SixRackUnits/refs/heads/main/assets/logo.png)](https://sixrackunits.substack.com)
